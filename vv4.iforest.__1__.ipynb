{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "result_dir = 'result'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = 'vv'\n",
    "pf = '__1__'\n",
    "\n",
    "Xval = np.load(f'{data_dir}/{af}3.v.X.{pf}.npy', allow_pickle=True)\n",
    "y_val = np.load(f'{data_dir}/{af}3.v.y.npy', allow_pickle=True)\n",
    "\n",
    "#? features names\n",
    "fts_names = [line.strip() for line in open(f'{data_dir}/{af}3.fts_cols.{pf}.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" split train test \"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, y_train, y_test = train_test_split(Xval, y_val, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535242, 63)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(fts_names)):\n",
    "#     print(i, fts_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, PrecisionRecallDisplay, f1_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    #? relabel to use classification metrics\n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    print(roc_auc)\n",
    "\n",
    "    # display = PrecisionRecallDisplay.from_predictions(y_true, y_pred)\n",
    "    # _ = display.ax_.set_title(\"2-class Precision-Recall curve\")\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_result(model, Xtr, Xt, model_name, selected_fts_names, roc_auc, expname='', config=None):\n",
    "    ra = '{:.2f}'.format(round(roc_auc * 100, 2))\n",
    "    # if ra <= 70: #? not good enough to even bother\n",
    "    #     return\n",
    "    \n",
    "    #? save model\n",
    "    pickle.dump(model, open(f'{result_dir}/{af}4.{pf}.{model_name}.{expname}.__{ra}__.model.pkl','wb'))\n",
    "\n",
    "    #? save transformed X as well\n",
    "    np.save(f'{result_dir}/{af}4.{pf}.{model_name}.{expname}.__{ra}__.data.tr.X.npy', Xtr)\n",
    "    np.save(f'{result_dir}/{af}4.{pf}.{model_name}.{expname}.__{ra}__.data.t.X.npy', Xt)\n",
    "    # np.save(f'{result_dir}/{af}4.{pf}.{model_name}.{expname}.__{ra}__.data.v.X.npy', Xv)\n",
    "\n",
    "    #? save fts\n",
    "    open(f'{result_dir}/{af}4.{pf}.{model_name}.{expname}.__{ra}__.fts.txt', 'w').write('\\n'.join(selected_fts_names))\n",
    "    \n",
    "    #? save config\n",
    "    if config is not None:\n",
    "        open(f'{result_dir}/{af}4.{pf}.{model_name}.{expname}.__{ra}__.config.txt', 'w').write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def test_param(x_train, x_test, n_estimators, contamination):\n",
    "    model = IsolationForest(n_estimators=n_estimators, max_samples=x_train.shape[0], contamination=contamination, n_jobs=10, verbose=1)\n",
    "\n",
    "    \"\"\" train \"\"\"\n",
    "    model.fit(x_train)\n",
    "\n",
    "    \"\"\" predict & evaluate on train set \"\"\"\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    #? evaluate\n",
    "    print('Evaluate on train set')\n",
    "    evaluate(y_train, y_train_pred)\n",
    "    print()\n",
    "\n",
    "    \"\"\" predict & evaluate on test set \"\"\"\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    #? evaluate\n",
    "    print('Evaluate on test set')\n",
    "    evaluate(y_test, y_test_pred)\n",
    "\n",
    "    del x_train, x_test\n",
    "    del y_test_pred, y_train_pred\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 02: Run on all features\n",
    "\n",
    "`Dur`, `sTos`, `dTos`, `Sport`, `Dport`, `TotPkts`, `TotBytes`, `SrcBytes`, `PktsPerSec`, `BytesPerSec`, `SrcBytesPerSec`, `BytesPerPkt`, `DstBytes`, `DstBytesPerSec`, `SportHex`, `DportHex`, `sTos_-1`, `sTos_0`, `sTos_1`, `sTos_2`, `sTos_3`, `dTos_-1`, `dTos_0`, `dTos_1`, `dTos_2`, `dTos_3`, `State_CON`, `State_alltcp`, `State_INT`, `State_S_`, `State_URP`, `State_ECO`, `State_RED`, `State_REQ`, `State_ECR`, `State_URH`, `State_TXD`, `State_URFIL`, `State_R_`, `State_URN`, `State_RSP`, `State_URHPRO`, `State_A_`, `State_other`, `Flag_nan`, `Flag_S`, `Flag_A`, `Flag_P`, `Flag_R`, `Flag_F`, `Proto_udp`, `Proto_tcp`, `Proto_icmp`, `Proto_rtp`, `Proto_rtcp`, `Proto_igmp`, `Proto_arp`, `Proto_other`, `Service_80`, `Service_443`, `Service_21`, `Service_22`, `Service_25`, `Service_6667`, `Service_other`\n",
    "\n",
    "The result increase, yet running time is much higher\n",
    "\n",
    "```\n",
    "CPU times: total: 2min 13s\n",
    "Wall time: 39.8 s\n",
    "\n",
    "CPU times: total: 13.7 s\n",
    "Wall time: 13.8 s\n",
    "\n",
    "[[751564  10016]\n",
    " [  1123   1839]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0     0.9985    0.9868    0.9926    761580\n",
    "           1     0.1551    0.6209    0.2482      2962\n",
    "\n",
    "    accuracy                         0.9854    764542\n",
    "   macro avg     0.5768    0.8039    0.6204    764542\n",
    "weighted avg     0.9952    0.9854    0.9898    764542\n",
    "\n",
    "0.8038563375096434\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dur, sTos, dTos, Sport, Dport, TotPkts, TotBytes, SrcBytes, PktsPerSec, BytesPerSec, SrcBytesPerSec, BytesPerPkt, DstBytes, DstBytesPerSec, SportHex, DportHex, sTos_-1, sTos_0, sTos_1, sTos_2, sTos_3, dTos_-1, dTos_0, dTos_1, dTos_2, dTos_3, State_CON, State_alltcp, State_INT, State_S_, State_URP, State_ECO, State_RED, State_REQ, State_ECR, State_URH, State_TXD, State_URFIL, State_R_, State_URN, State_RSP, State_URHPRO, State_A_, State_other, Flag_nan, Flag_S, Flag_A, Flag_P, Flag_R, Flag_F, Proto_udp, Proto_tcp, Proto_icmp, Proto_rtp, Proto_rtcp, Proto_igmp, Proto_arp, Proto_other, Service_80, Service_443, Service_21, Service_22, Service_25, Service_6667, Service_other'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" select features \"\"\"\n",
    "selected_fts_names__02 = fts_names[:]\n",
    "', '.join(selected_fts_names__02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(535242, 65)\n"
     ]
    }
   ],
   "source": [
    "X_train__02 = Xtrain[:,:]\n",
    "X_test__02 = Xtest[:,:]\n",
    "\n",
    "print(X_train__02.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:   10.0s remaining:   40.3s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:   10.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on train set\n",
      "[[502740  24455]\n",
      " [  5740   2307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9887    0.9536    0.9708    527195\n",
      "           1     0.0862    0.2867    0.1326      8047\n",
      "\n",
      "    accuracy                         0.9436    535242\n",
      "   macro avg     0.5375    0.6202    0.5517    535242\n",
      "weighted avg     0.9751    0.9436    0.9582    535242\n",
      "\n",
      "0.6201518408422305\n",
      "\n",
      "Evaluate on test set\n",
      "[[215213  10716]\n",
      " [  2447   1014]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9888    0.9526    0.9703    225929\n",
      "           1     0.0864    0.2930    0.1335      3461\n",
      "\n",
      "    accuracy                         0.9426    229390\n",
      "   macro avg     0.5376    0.6228    0.5519    229390\n",
      "weighted avg     0.9751    0.9426    0.9577    229390\n",
      "\n",
      "0.6227740388952906\n"
     ]
    }
   ],
   "source": [
    "test_param(n_estimators=50, contamination=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    9.3s remaining:   37.6s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:   10.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on train set\n",
      "[[524109   3086]\n",
      " [  7921    126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9851    0.9941    0.9896    527195\n",
      "           1     0.0392    0.0157    0.0224      8047\n",
      "\n",
      "    accuracy                         0.9794    535242\n",
      "   macro avg     0.5122    0.5049    0.5060    535242\n",
      "weighted avg     0.9709    0.9794    0.9751    535242\n",
      "\n",
      "0.5049021938353658\n",
      "\n",
      "Evaluate on test set\n",
      "[[224540   1389]\n",
      " [  3411     50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9850    0.9939    0.9894    225929\n",
      "           1     0.0347    0.0144    0.0204      3461\n",
      "\n",
      "    accuracy                         0.9791    229390\n",
      "   macro avg     0.5099    0.5041    0.5049    229390\n",
      "weighted avg     0.9707    0.9791    0.9748    229390\n",
      "\n",
      "0.5041493712865682\n"
     ]
    }
   ],
   "source": [
    "test_param(n_estimators=50, contamination=0.006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    7.7s remaining:   31.1s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on train set\n",
      "[[503169  24026]\n",
      " [  5310   2737]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9896    0.9544    0.9717    527195\n",
      "           1     0.1023    0.3401    0.1573      8047\n",
      "\n",
      "    accuracy                         0.9452    535242\n",
      "   macro avg     0.5459    0.6473    0.5645    535242\n",
      "weighted avg     0.9762    0.9452    0.9594    535242\n",
      "\n",
      "0.647276742729914\n",
      "\n",
      "Evaluate on test set\n",
      "[[215417  10512]\n",
      " [  2283   1178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9895    0.9535    0.9712    225929\n",
      "           1     0.1008    0.3404    0.1555      3461\n",
      "\n",
      "    accuracy                         0.9442    229390\n",
      "   macro avg     0.5451    0.6469    0.5633    229390\n",
      "weighted avg     0.9761    0.9442    0.9589    229390\n",
      "\n",
      "0.6469180825626465\n"
     ]
    }
   ],
   "source": [
    "test_param(n_estimators=40, contamination=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    8.0s remaining:   32.3s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on train set\n",
      "[[522183   5012]\n",
      " [  7706    341]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9855    0.9905    0.9880    527195\n",
      "           1     0.0637    0.0424    0.0509      8047\n",
      "\n",
      "    accuracy                         0.9762    535242\n",
      "   macro avg     0.5246    0.5164    0.5194    535242\n",
      "weighted avg     0.9716    0.9762    0.9739    535242\n",
      "\n",
      "0.5164345610341037\n",
      "\n",
      "Evaluate on test set\n",
      "[[223714   2215]\n",
      " [  3319    142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9854    0.9902    0.9878    225929\n",
      "           1     0.0602    0.0410    0.0488      3461\n",
      "\n",
      "    accuracy                         0.9759    229390\n",
      "   macro avg     0.5228    0.5156    0.5183    229390\n",
      "weighted avg     0.9714    0.9759    0.9736    229390\n",
      "\n",
      "0.5156123197435686\n"
     ]
    }
   ],
   "source": [
    "test_param(n_estimators=40, contamination=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    5.7s remaining:   23.1s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on train set\n",
      "[[502711  24484]\n",
      " [  5769   2278]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9887    0.9536    0.9708    527195\n",
      "           1     0.0851    0.2831    0.1309      8047\n",
      "\n",
      "    accuracy                         0.9435    535242\n",
      "   macro avg     0.5369    0.6183    0.5508    535242\n",
      "weighted avg     0.9751    0.9435    0.9582    535242\n",
      "\n",
      "0.618322423031074\n",
      "\n",
      "Evaluate on test set\n",
      "[[215262  10667]\n",
      " [  2458   1003]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9887    0.9528    0.9704    225929\n",
      "           1     0.0859    0.2898    0.1326      3461\n",
      "\n",
      "    accuracy                         0.9428    229390\n",
      "   macro avg     0.5373    0.6213    0.5515    229390\n",
      "weighted avg     0.9751    0.9428    0.9578    229390\n",
      "\n",
      "0.6212933439548949\n"
     ]
    }
   ],
   "source": [
    "test_param(n_estimators=30, contamination=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    6.8s remaining:   27.6s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on train set\n",
      "[[522097   5098]\n",
      " [  7792    255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9903    0.9878    527195\n",
      "           1     0.0476    0.0317    0.0381      8047\n",
      "\n",
      "    accuracy                         0.9759    535242\n",
      "   macro avg     0.5165    0.5110    0.5129    535242\n",
      "weighted avg     0.9712    0.9759    0.9735    535242\n",
      "\n",
      "0.5110093909734327\n",
      "\n",
      "Evaluate on test set\n",
      "[[223672   2257]\n",
      " [  3370     91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9852    0.9900    0.9876    225929\n",
      "           1     0.0388    0.0263    0.0313      3461\n",
      "\n",
      "    accuracy                         0.9755    229390\n",
      "   macro avg     0.5120    0.5082    0.5095    229390\n",
      "weighted avg     0.9709    0.9755    0.9731    229390\n",
      "\n",
      "0.5081515574177444\n"
     ]
    }
   ],
   "source": [
    "test_param(n_estimators=30, contamination=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train__02\n",
    "del X_test__02"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
